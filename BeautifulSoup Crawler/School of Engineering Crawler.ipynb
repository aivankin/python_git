{
 "metadata": {
  "name": "",
  "signature": "sha256:fe175529d6a8e226e257645b3ac414cea7f502872a498c1dbf76a13d3d9580f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is an example of a BeautifulSoup crawler, which goes through the directory of professors from the school of engineering at Stanford and extracts information about them (iPython, BeautifulSoup, Pandas)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import re\n",
      "import pandas as pd\n",
      "import time\n",
      "import pickle\n",
      "\n",
      "df = pd.DataFrame([\"Name\", \"Title\",\"Department\",\"Email\",\"Phone\",\"School\"]).T\n",
      "\n",
      "letter = {'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'}\n",
      "\n",
      "for item in letter:\n",
      "    url = 'http://engineering.stanford.edu/research-faculty/profile-faculty/'+item+'?page='\n",
      "    profiles = []\n",
      "    for i in range(0,2):\n",
      "        initial_url = url+str(i)+'#'\n",
      "        r = requests.get(initial_url)\n",
      "        soup = BeautifulSoup(r.content)\n",
      "        \n",
      "\n",
      "# Extraxting relative links for professors\n",
      "\n",
      "        links = soup.find_all('div', class_='span7')\n",
      "        for link in links:\n",
      "            linkee = link.find('a')\n",
      "            profiles.append(linkee.get('href'))\n",
      "            url_base = 'http://engineering.stanford.edu'\n",
      "\n",
      "    for profile in profiles:\n",
      "        url = url_base + profile.strip()            \n",
      "        r = requests.get(url)\n",
      "        if r:\n",
      "            soup = BeautifulSoup(r.content)\n",
      "            if soup:\n",
      "# Name\n",
      "                Name = soup.find('h1')\n",
      "                sep = ','\n",
      "                name = Name.text.split(sep,1)[0]\n",
      "\n",
      "# Title and Department TD\n",
      "\n",
      "                T = []\n",
      "                D = []\n",
      "                if soup.find('div', id='academicAppointmentsContent'):\n",
      "                    TD = soup.find('div', id='academicAppointmentsContent').find_all('li')\n",
      "                    for item in TD:\n",
      "                        title = item.text.split(sep,1)[0].strip()\n",
      "                        department = item.text.split(sep,1)[1].strip()\n",
      "                        if 'Professor' in str(title):\n",
      "                            T.append(title)\n",
      "                            D.append(department)\n",
      "                else:\n",
      "                    T.append('')\n",
      "                    D.append('')\n",
      "\n",
      "# Phone\n",
      "                if soup.find('div', class_='contact-info'):\n",
      "                    Phone = soup.find('div', class_='contact-info').find('ul',class_='unstyled phone-number')\n",
      "                    if Phone:\n",
      "                        phone = Phone.text.replace('Tel:','').replace('\\n',' ').strip()\n",
      "                    else:\n",
      "                        phone = ''\n",
      "                else:\n",
      "                    phone = ''\n",
      "\n",
      "# Email\n",
      "\n",
      "                if soup.find('div', class_='contact-info'):\n",
      "                    Email = soup.find('div', class_='contact-info').find('a', class_='email')\n",
      "                    email = Email.text.strip() \n",
      "                else:\n",
      "                    email = ''\n",
      "\n",
      "            new_df=pd.DataFrame()\n",
      "\n",
      "            for i in range(len(T)):\n",
      "                new_df = pd.DataFrame([name, T[i], D[i], email, phone, 'Engineering']).T\n",
      "                df = pd.DataFrame(df).append(new_df)\n",
      "\n",
      "                \n",
      "df_no_dup = df.drop_duplicates()\n",
      "df_no_dup.to_csv('Engineering_School_All.csv',sep = '\\t', encoding = 'utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}