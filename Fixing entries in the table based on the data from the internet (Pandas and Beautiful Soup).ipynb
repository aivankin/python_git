{
 "metadata": {
  "name": "",
  "signature": "sha256:9e7d4f3eb3bbf67b89ff82bded09b8f662d68a10795c9de2eff603e9f12eaf95"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import numpy as np\n",
      "import random\n",
      "from datetime import datetime, date, time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "In this part we read the data from 'All.csv' file and make the list of all department entries in the file\n",
      "\n",
      "We also lower the case for the list and replace '&' with 'and'\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pandas.io.parsers.read_csv('All.csv')\n",
      "current_departments_list_unsub = data['Department'].str.lower()\n",
      "\n",
      "current_departments_list = []\n",
      "for itemz in current_departments_list_unsub:\n",
      "    departmentz = str(itemz).replace('&','and')\n",
      "    current_departments_list.append(departmentz)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "In this part we crawl through the Stanford website to extract the list of all departments and corresponding schools they are affiliated with.\n",
      "\n",
      "We create a dictionary and a standalone list of all departments with lowercase entries and with '&' also substituted with 'and'\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import re\n",
      "\n",
      "# Making a list of departments and \n",
      "initial_url = 'http://www.stanford.edu/academics/departments#school'\n",
      "r = requests.get(initial_url)\n",
      "soup = BeautifulSoup(r.content)\n",
      "department_list = []        \n",
      "\n",
      "### Complete list of schools and corresponding departments\n",
      "complete_list = [[],[]]\n",
      "\n",
      "department_dictionary = {}\n",
      "\n",
      "### School of Business School BizSch\n",
      "soupBizSch = soup.find('div', id = 'list-school').find('h3')\n",
      "\n",
      "department = u'Graduate School of Business'\n",
      "school = u'Graduate School of Business'\n",
      "\n",
      "department_dictionary[department.strip()] = school.strip()\n",
      "\n",
      "complete_list[0].append(school)\n",
      "complete_list[1].append(department)\n",
      "\n",
      "### ESS School\n",
      "soupESSSch = soup.find('div', id = 'list-school').find('h3').find_next('h3')\n",
      "soupESS = soupESSSch.find_next('ul')\n",
      "\n",
      "soupESSlinks = soupESS.find_all('a')\n",
      "\n",
      "school = u'School of Earth Sciences'\n",
      "\n",
      "for itemz in soupESSlinks:\n",
      "    department = itemz.text.replace('&','and')\n",
      "    complete_list[0].append(school)\n",
      "    complete_list[1].append(department)\n",
      "    department_dictionary[department.strip()] = school.strip()\n",
      "     \n",
      "    \n",
      "### School of Education EduSch\n",
      "soupEduSch = soup.find('div', id = 'list-school').find('h3').find_next('h3').find_next('h3')\n",
      "\n",
      "department = u'School of Education'\n",
      "school = u'School of Education'\n",
      "\n",
      "department_dictionary[department.strip()] = school.strip()\n",
      "complete_list[0].append(school.strip())\n",
      "complete_list[1].append(department.strip())\n",
      "\n",
      "\n",
      "### School of Engineering EngSch\n",
      "soupEngSch = soup.find('div', id = 'list-school').find('h3').find_next('h3').find_next('h3').find_next('h3')\n",
      "soupEng = soupEngSch.find_next('ul')\n",
      "\n",
      "soupEnglinks = soupEng.find_all('a')\n",
      "\n",
      "school = u'School of Engineering'\n",
      "\n",
      "for itemz in soupEnglinks:\n",
      "    department = itemz.text.replace('&','and')\n",
      "    complete_list[0].append(school)\n",
      "    complete_list[1].append(department)\n",
      "    department_dictionary[department.strip()] = school.strip()\n",
      "    \n",
      "### Humanities & Sciences HSS\n",
      "soupHSSch = soup.find('div', id = 'list-school').find('h3').find_next('h3').find_next('h3').find_next('h3').find_next('h3')\n",
      "soupHSS = soupHSSch.find_next('ul')\n",
      "\n",
      "soupHSSlinks = soupHSS.find_all('a')\n",
      "\n",
      "school = u'School of Humanities and Sciences'\n",
      "\n",
      "for itemz in soupHSSlinks:\n",
      "    department = itemz.text.replace('&','and')\n",
      "    complete_list[0].append(school)\n",
      "    complete_list[1].append(department)\n",
      "    department_dictionary[department.strip()] = school.strip()\n",
      "    \n",
      "### Law School LawSch\n",
      "soupLawSch = soup.find('div', id = 'list-school').find('h3').find_next('h3').find_next('h3').find_next('h3').find_next('h3').find_next('h3')\n",
      "\n",
      "department = u'Law School'\n",
      "school = u'Law School'\n",
      "department_dictionary[department.strip()] = school.strip()\n",
      "\n",
      "complete_list[0].append(school)\n",
      "complete_list[1].append(department)\n",
      "\n",
      "### Med School MDSch\n",
      "soupMDSch = soup.find('div', id = 'list-school').find('h3').find_next('h3').find_next('h3').find_next('h3').find_next('h3').find_next('h3').find_next('h3')\n",
      "soupMD = soupMDSch.find_next('ul')\n",
      "\n",
      "soupMDlinks = soupMD.find_all('a')\n",
      "\n",
      "school = u'School of Medicine'\n",
      "\n",
      "for itemz in soupMDlinks:\n",
      "    department = itemz.text.replace('&','and')\n",
      "    if department == 'Otolaryngology (Head and Neck Surgery)':\n",
      "        department = u'Otolaryngology'\n",
      "        \n",
      "    complete_list[0].append(school)\n",
      "    complete_list[1].append(department)\n",
      "    department_dictionary[department.strip()] = school.strip()\n",
      "\n",
      "department_list = []\n",
      "\n",
      "for itemz in complete_list[1]:\n",
      "    department = itemz.lower().strip()\n",
      "    department_list.append(department) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "In this part, we compare if a string or substring of the Department or Academic area entry in 'All.csv' file matches the entries in the list of all department. If a partial match is found, the correct name is assigned to the Department cell of the corresponding row. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_indeces = data.index.tolist()\n",
      "\n",
      "# Find indeces where department is good from the very beginning\n",
      "int_good_indeces = []\n",
      "for i in range (len(current_departments_list)):\n",
      "    if current_departments_list[i] in department_list:\n",
      "        int_good_indeces.append(i)\n",
      "        \n",
      "# Find the complementary indeces, where the department entry is wrong\n",
      "        \n",
      "bad_indeces = []\n",
      "for item in all_indeces:\n",
      "    if item not in int_good_indeces:\n",
      "        bad_indeces.append(item)\n",
      "\n",
      "# Go through bad entries and check if part of the department name is the right entry and fix it        \n",
      "fixed_indeces = []\n",
      "sep = '-'\n",
      "for item in bad_indeces:\n",
      "    text = data.loc[item,'Department']\n",
      "    if text and isinstance(text,str): \n",
      "        text_split = text.split(sep,1)\n",
      "        department_w_n = text_split[0].strip().lower()\n",
      "        department_append_w_n = text_split[0].strip()\n",
      "        \n",
      "        department = department_w_n.replace('&','and')\n",
      "        department_append = department_append_w_n.replace('&','and')\n",
      "        \n",
      "        if department == 'psychiatry and behavioral science':\n",
      "            department = 'psychiatry and behavioral sciences'\n",
      "            department_append = 'Psychiatry and Behavioral Sciences'\n",
      "                    \n",
      "        if len(text_split)>1:\n",
      "            academic_area_append_w_n = text_split[1].strip()\n",
      "            academic_area_to_check_w_n = academic_area_append_w_n.lower()\n",
      "            \n",
      "            academic_area_append = academic_area_append_w_n.replace('&','and')\n",
      "            academic_area_to_check = academic_area_to_check_w_n.replace('&','and')\n",
      "            \n",
      "            if academic_area_to_check == 'psychiatry and behavioral science':\n",
      "                academic_area_to_check = 'psychiatry and behavioral sciences'\n",
      "                academic_area_append = 'Psychiatry and Behavioral Sciences'\n",
      "            \n",
      "            if academic_area_to_check in department_list:\n",
      "                data.loc[item,'Department'] = academic_area_append\n",
      "                fixed_indeces.append(item)\n",
      "                \n",
      "        if department in department_list:\n",
      "            data.loc[item,'Department'] = department_append\n",
      "            data.loc[item,'Academic area'] = academic_area_append\n",
      "            fixed_indeces.append(item)\n",
      "        \n",
      "fixed_indeces = []\n",
      "sep = ','\n",
      "for item in bad_indeces:\n",
      "    text = data.loc[item,'Department']\n",
      "    if text and isinstance(text,str): \n",
      "        text_split = text.split(sep,1)\n",
      "        \n",
      "        department_w_n = text_split[0].strip().lower()\n",
      "        department_append_w_n = text_split[0].strip()\n",
      "        \n",
      "        department = department_w_n.replace('&','and')\n",
      "        department_append = department_append_w_n.replace('&','and')\n",
      "        \n",
      "        if department == 'psychiatry and behavioral science':\n",
      "            department = 'psychiatry and behavioral sciences'\n",
      "            department_append = 'Psychiatry and Behavioral Sciences'\n",
      "        \n",
      "        if len(text_split)>1:\n",
      "            academic_area_append_w_n = text_split[1].strip()\n",
      "            academic_area_to_check_w_n = academic_area_append_w_n.lower()\n",
      "            \n",
      "            academic_area_append = academic_area_append_w_n.replace('&','and')\n",
      "            academic_area_to_check = academic_area_to_check_w_n.replace('&','and')\n",
      "            \n",
      "            if academic_area_to_check == 'psychiatry and behavioral science':\n",
      "                academic_area_to_check = 'psychiatry and behavioral sciences'\n",
      "                academic_area_append = 'Psychiatry and Behavioral Sciences'\n",
      "            \n",
      "            if academic_area_to_check in department_list:\n",
      "                data.loc[item,'Department'] = academic_area_append\n",
      "                fixed_indeces.append(item)\n",
      "                \n",
      "        if department in department_list:\n",
      "            data.loc[item,'Department'] = department_append\n",
      "            data.loc[item,'Academic area'] = academic_area_append\n",
      "            fixed_indeces.append(item)\n",
      "\n",
      "# More fixed indeces by checking the second part      \n",
      "more_fixed_indeces = []\n",
      "sep = ','\n",
      "for item in bad_indeces:\n",
      "    text = data.loc[item,'Department']\n",
      "    if text and isinstance(text,str): \n",
      "        text_split = text.split(sep,1)        \n",
      "        if len(text_split)>1:\n",
      "            department_w_n = text_split[1].strip().lower()\n",
      "            department_append_w_n = text_split[1].strip()         \n",
      "        \n",
      "            department = department_w_n.replace('&','and')\n",
      "            department_append = department_append_w_n.replace('&','and')\n",
      "        \n",
      "            if department == 'psychiatry and behavioral science':\n",
      "                department = 'psychiatry and behavioral sciences'\n",
      "                department_append = 'Psychiatry and Behavioral Sciences'\n",
      "                \n",
      "        else: demartment = 'na'\n",
      "            \n",
      "        if department in department_list:\n",
      "            data.loc[item,'Department'] = department_append\n",
      "            more_fixed_indeces.append(item)\n",
      "            \n",
      "sep = '-'\n",
      "for item in bad_indeces:\n",
      "    text = data.loc[item,'Department']\n",
      "    if text and isinstance(text,str): \n",
      "        text_split = text.split(sep,1)        \n",
      "        if len(text_split)>1:\n",
      "            department_w_n = text_split[1].strip().lower()\n",
      "            department_append_w_n = text_split[1].strip()         \n",
      "        \n",
      "            department = department_w_n.replace('&','and')\n",
      "            department_append = department_append_w_n.replace('&','and')\n",
      "        \n",
      "            if department == 'psychiatry and behavioral science':\n",
      "                department = 'psychiatry and behavioral sciences'\n",
      "                department_append = 'Psychiatry and Behavioral Sciences'\n",
      "            \n",
      "            \n",
      "        else: demartment = 'na'\n",
      "        if department in department_list:\n",
      "            data.loc[item,'Department'] = department_append\n",
      "            more_fixed_indeces.append(item)    \n",
      "            \n",
      " \n",
      "# One more scenario\n",
      "\n",
      "even_more_fixed_indeces = []\n",
      "\n",
      "for item in all_bad_indeces:\n",
      "    text = data.loc[item,'Department']\n",
      "    if text and isinstance(text,str): \n",
      "        text_split = text.split(',',1)\n",
      "        if len(text_split)>1:\n",
      "            text_split2 = text_split[1].split('-',1)\n",
      "            \n",
      "            department_w_n = text_split2[0].strip().lower()\n",
      "            department = department_w_n.replace('&','and')\n",
      "            \n",
      "            if department == 'psychiatry and behavioral science':\n",
      "                department = 'psychiatry and behavioral sciences'\n",
      "                department_append = 'Psychiatry and Behavioral Sciences'\n",
      "            \n",
      "            if department in department_list:\n",
      "                data.loc[item,'Department'] = department_append\n",
      "                even_more_fixed_indeces.append(item)   \n",
      "            \n",
      "            \n",
      "# Find indeces for yet unfixed entries\n",
      "yet_unfixed_indeces = []\n",
      "for item in all_indeces:\n",
      "    if (item not in int_good_indeces) and (item not in fixed_indeces) and (item not in more_fixed_indeces) and (item not in even_more_fixed_indeces):\n",
      "        yet_unfixed_indeces.append(item)\n",
      "        \n",
      "        \n",
      "# Find instances when Academic area matches Department name and fix i\n",
      "academic_area_fixed_indeces = []\n",
      "for item in yet_unfixed_indeces:\n",
      "    text = data.loc[item,'Academic area']\n",
      "    \n",
      "    if text and isinstance(text,str):\n",
      "        \n",
      "        academic_area_append_w_n = text.strip()\n",
      "        academic_area_to_check_w_n = text.strip().lower()\n",
      "            \n",
      "        academic_area_append = academic_area_append_w_n.replace('&','and')\n",
      "        academic_area_to_check = academic_area_to_check_w_n.replace('&','and')\n",
      "        \n",
      "        if academic_area_to_check == 'psychiatry and behavioral science':\n",
      "            academic_area_to_check = 'psychiatry and behavioral sciences'\n",
      "            academic_area_append = 'Psychiatry and Behavioral Sciences'\n",
      "        \n",
      "        if academic_area_to_check in department_list:\n",
      "            data.loc[item,'Department'] = academic_area_append\n",
      "            academic_area_fixed_indeces.append(item)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "In this part we go through all the indeces fixed in different scenarios from the previous part and make lists of all bad and good indeces\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_good_indeces = []\n",
      "all_bad_indeces = []\n",
      "\n",
      "for item in all_indeces:\n",
      "    if item in yet_unfixed_indeces:\n",
      "        if item not in academic_area_fixed_indeces:\n",
      "            all_bad_indeces.append(item)\n",
      "\n",
      "for item in all_indeces:\n",
      "    if item not in all_bad_indeces:\n",
      "         all_good_indeces.append(item)\n",
      "            \n",
      "all_all_indeces = all_good_indeces + all_bad_indeces\n",
      "\n",
      "for itemz in all_good_indeces:\n",
      "    text = data.loc[itemz,'Department']    \n",
      "    if text in department_dictionary.keys():\n",
      "        data.loc[itemz,'School'] = department_dictionary[text]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Here we create pandas dataframes of all good (initially good and fixed), bad (unfixed), and all entries.\n",
      "\n",
      "Then we sort these dataframes by last name and save into three csv files.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_good_data = pandas.DataFrame()\n",
      "for itemz in all_good_indeces:\n",
      "        all_good_data = pandas.DataFrame(all_good_data).append(data.irow(int(itemz)))\n",
      "\n",
      "all_bad_data = pandas.DataFrame()\n",
      "for itemz in all_bad_indeces:\n",
      "        all_bad_data = pandas.DataFrame(all_bad_data).append(data.irow(int(itemz)))\n",
      "        \n",
      "all_all_data = pandas.DataFrame()\n",
      "for itemz in all_all_indeces:\n",
      "        all_all_data = pandas.DataFrame(all_all_data).append(data.irow(int(itemz)))\n",
      "\n",
      "\n",
      "all_good_data_sorted = all_good_data.sort(['Last name'])\n",
      "all_bad_data_sorted = all_bad_data.sort(['Last name'])\n",
      "all_all_data_sorted = all_all_data.sort(['Last name'])\n",
      "\n",
      "all_good_data_sorted.to_csv('All_Good_Data.csv',sep = '\\t',header=True,cols=['Last name', 'First name', 'Position', 'Academic area',\n",
      "       'Department', 'e-mail', 'phone', 'Home page', 'video', 'H-factor',\n",
      "       'Total# of publications', 'Tags to the field', 'School',\n",
      "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
      "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20',\n",
      "       'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24',\n",
      "       'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28',\n",
      "       'Unnamed: 29', 'Unnamed: 30'])\n",
      "\n",
      "all_bad_data_sorted.to_csv('All_Bad_Data.csv',sep = '\\t',header=True,cols=['Last name', 'First name', 'Position', 'Academic area',\n",
      "       'Department', 'e-mail', 'phone', 'Home page', 'video', 'H-factor',\n",
      "       'Total# of publications', 'Tags to the field', 'School',\n",
      "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
      "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20',\n",
      "       'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24',\n",
      "       'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28',\n",
      "       'Unnamed: 29', 'Unnamed: 30'])\n",
      "\n",
      "all_all_data_sorted.to_csv('All_All_Data.csv',sep = '\\t',header=True,cols=['Last name', 'First name', 'Position', 'Academic area',\n",
      "       'Department', 'e-mail', 'phone', 'Home page', 'video', 'H-factor',\n",
      "       'Total# of publications', 'Tags to the field', 'School',\n",
      "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
      "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20',\n",
      "       'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24',\n",
      "       'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28',\n",
      "       'Unnamed: 29', 'Unnamed: 30'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}